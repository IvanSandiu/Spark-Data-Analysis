# Data Analysis with Spark

This repository contains a Google Colab Notebook where I explore employee data using **PySpark**.  
The notebook demonstrates how to load data, define schemas, run SQL queries, and perform common transformations and aggregations in Spark.  

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IvanSandiu/Spark-Data-Analysis/blob/main/DataAnalysis_Spark.ipynb)

---

## ðŸ“Œ Overview
In this project, I worked with an employee dataset and applied a series of Spark operations, including:

- Loading data from a CSV file into a Spark DataFrame  
- Defining and displaying schemas  
- Creating temporary views for SQL queries  
- Filtering and aggregating data (average salary, total salary by department, max salary by age, etc.)  
- Adding computed columns (e.g., salary with bonus)  
- Sorting and grouping operations  
- Performing a self-join on employee data  

---

## ðŸš€ Technologies Used
- Python 3  
- Apache Spark (PySpark)  
- Google Colab  

---

## ðŸŽ¯ Purpose
The notebook was created as a hands-on way to strengthen my skills in **data analysis and big data frameworks**.  
It highlights how Spark SQL and DataFrames can be combined to efficiently process structured data.  

---

## ðŸ“‚ File
- `DataAnalysis_Spark.ipynb`: Main notebook with the analysis  

---

## ðŸ”— How to Run
1. Click the **Open in Colab** button above.  
2. Make sure to upload the `employees.csv` dataset if needed.  
3. Run the cells step by step to reproduce the analysis.  

